<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <meta name="google-site-verification" content="oqOYUzFND7pSD14Pcr9s24FN0U4rx-JLC_cmup3bndc" />

  <title>Patrick Lange | publications</title>
  <meta name="description" content="Personal website and 'speech-controlled' blog.
">

  <link rel="shortcut icon" href="https://www.langep.com/assets/img/favicon.ico">

  <link rel="stylesheet" href="https://www.langep.com/assets/css/main.css">
  <link rel="canonical" href="https://www.langep.com/publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Patrick</strong> Lange
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="https://www.langep.com/">about</a>

        <!-- Blog -->
        <a class="page-link" href="https://www.langep.com/blog/">blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="https://www.langep.com/publications/">publications</a>
          
        
          
        
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="https://www.langep.com/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description"><a href="#books-and-chapters">[Books and Chapters]</a> <a href="#articles">[Articles]</a> <a href="#theses">[Theses]</a> <a href="#patents">[Patents]</a> <a href="#reports">[Reports]</a></h5>
  </header>

  <article class="post-content publications clearfix">
    <h3 id="books-and-chapters" class="category">Books and Chapters</h3>
<ol class="bibliography"><li>


<div id="qian2019automatic">
  

  
  <span class="author">
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    and
    
    
    Evanini, Keelan
    
    
    
    
  </span>
  

  <span class="title">Automatic Speech Recognition for Automated Speech Scoring</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Automated Speaking Assessment: Using Language Technologies to Score Spontaneous Speech,</em>
    

    
    2019
    
  </span>

  
  

  <span class="links">
    
    
    
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Yu2017a">
  

  
  <span class="author">
    
    
    
    
    Yu, Zhou,
    
    
    
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    and
    
    
    Suendermann‐Oeft, David
    
    
    
    
  </span>
  

  <span class="title">An Open-Source Dialog System with Real-Time Engagement Tracking for Job Interview Training Applications</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Advanced Social Interaction with Agents,</em>
    

    
    2019
    
  </span>

  
  

  <span class="links">
    
    [<a class="abstract">Abs</a>]
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Yu2017a.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>\textcopyright 2019, Springer International Publishing AG, part of Springer Nature. In complex conversation tasks, people react to their interlocutor’s state, such as uncertainty and engagement to improve conversation effectiveness Forbes-Riley and Litman (Adapting to student uncertainty improves tutoring dialogues, pp 33–40, 2009 [2]). If a conversational system reacts to a user’s state, would that lead to a better conversation experience? To test this hypothesis, we designed and implemented a dialog system that tracks and reacts to a user’s state, such as engagement, in real time. We designed and implemented a conversational job interview task based on the proposed framework. The system acts as an interviewer and reacts to user’s disengagement in real-time with positive feedback strategies designed to re-engage the user in the job interview process. Experiments suggest that users speak more while interacting with the engagement-coordinated version of the system as compared to a non-coordinated version. Users also reported the former system as being more engaging and providing a better user experience.</p>
  </span>
  
</div></li>
<li>


<div id="Yu2017">
  

  
  <span class="author">
    
    
    
    
    Yu, Zhou,
    
    
    
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Mundkowsky, Robert,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Ivanov, Alexei V.,
    
    
    
    
    
    
    
    Black, Alan W.,
    
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Multimodal HALEF: An Open-Source Modular Web-Based Multimodal Dialog Framework</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Dialogues with Social Robots,</em>
    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Yu2017.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Ramanarayanan2017a">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Mundkowsky, Robert,
    
    
    
    
    
    
    
    Ivanov, Alexei V.,
    
    
    
    
    
    
    
    Yu, Zhou,
    
    
    
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    and
    
    
    Evanini, Keelan
    
    
    
    
  </span>
  

  <span class="title">Assembling the jigsaw: How multiple open standards are synergistically combined in the HALEF multimodal dialog system</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Multimodal Interaction with W3C Standards,</em>
    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ramanarayanan2017a.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li></ol>

<h3 id="articles" class="category">Articles</h3>
<ol class="bibliography"><li>


<div id="Loukina2019">
  

  
  <span class="author">
    
    
    
    
    Loukina, Anastassia,
    
    
    
    
    
    
    
    Klebanov, Beata Beigman,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    
    
    Gyawali, Binod,
    
    
    
    
    
    
    
    Madnani, Nitin,
    
    
    
    
    
    
    
    Misra, Abhinav,
    
    
    
    
    
    
    
    Zechner, Klaus,
    
    
    
    
    
    
    
    Wang, Zuowei,
    
    
    
    
    
    and
    
    
    Sabatini, John
    
    
    
    
  </span>
  

  <span class="title">Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of Interspeech, 20th Annual Conference of the International Speech Communication Association,</em>
    

    
    2019
    
  </span>

  
  

  <span class="links">
    
    [<a class="abstract">Abs</a>]
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Loukina2019.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Use of speech technologies in the classroom is often limited by the inferior acoustic conditions as well as other factors that might affect the quality of the recordings. We describe My-TurnToRead, an e-book-based app designed to support an inter-leaved listening and reading experience, where the child takes turns reading aloud with a virtual partner. The child’s reading turns are recorded, and processed by an automated speech analysis system in order to provide feedback or track improvement in reading skill. We describe the architecture of the speech processing back-end and evaluate system performance on the data collected in several summer camps where children used the app on consumer-grade devices as part of the camp programming. We show that while the quality of the audio recordings varies greatly, our estimates of student oral reading fluency are very good: for example, the correlation between ASR-based and transcription-based estimates of reading fluency at the speaker level is r=0.93. These are also highly correlated with an external measure of reading comprehension.</p>
  </span>
  
</div></li>
<li>


<div id="Madnani2019">
  

  
  <span class="author">
    
    
    
    
    Madnani, Nitin,
    
    
    
    
    
    
    
    Klebanov, Beata Beigman,
    
    
    
    
    
    
    
    Loukina, Anastassia,
    
    
    
    
    
    
    
    Gyawali, Binod,
    
    
    
    
    
    
    
    Sabatini, John,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Flor, Michael,
    
    
    
    
    
    
    
    Sabatini, John,
    
    
    
    
    
    and
    
    
    Flor, Michael
    
    
    
    
  </span>
  

  <span class="title">My Turn To Read: An Interleaved E-book Reading Tool for Developing and Struggling Readers</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of ACL, 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations,</em>
    

    
    2019
    
  </span>

  
  

  <span class="links">
    
    [<a class="abstract">Abs</a>]
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Madnani2019.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Literacy is crucial for functioning in modern society. It underpins everything from educational attainment and employment opportunities to health outcomes. We describe My Turn To Read, an app that uses interleaved reading to help developing and struggling readers improve reading skills while reading for meaning and pleasure. We hypothesize that the longer-term impact of the app will be to help users become better, more confident readers with an increased stamina for extended reading. We describe the technology and present preliminary evidence in support of this hypothesis.</p>
  </span>
  
</div></li>
<li>


<div id="Qian2019">
  

  
  <span class="author">
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    
    
    Pugh, Robert,
    
    
    
    
    
    
    
    Ubale, Rutuja,
    
    
    
    
    
    
    
    Mulholland, Matthew,
    
    
    
    
    
    and
    
    
    Wang, Xinhao
    
    
    
    
  </span>
  

  <span class="title">Neural Approaches to Automated Speech Scoring of Monologue and Dialogue Responses</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of ICASSP, 44th IEEE International Conference on Acoustics, Speech and Signal Processing,</em>
    

    
    2019
    
  </span>

  
  

  <span class="links">
    
    [<a class="abstract">Abs</a>]
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Qian2019.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>\textcopyright 2019 IEEE. We present Neural Network (NN) approaches to the automated assessment of non-native spontaneous speech in a monologic task and a simulated dialogic task. Three attention-based Bidirectional Long Short-Term Memory (BLSTM) Recurrent Neural Networks (RNN) are employed to learn three dimensions (i.e., delivery, language use, and content) of scoring rubrics for the spoken responses. The prompts or turn history information are encoded to low-dimensional vectors by either a BLSTM-RNN or an end-to-end memory network (MemN2N) and used as the conditions of the inputs of the NN for rating the subscore of content. The three subscores are fused together to generate a holistic score. The experimental results show that our approaches significantly outperform the conventional approaches to speech scoring and the correlations of automatically predicted scores with the reference human scores are higher than human-human agreement levels for both tasks.</p>
  </span>
  
</div></li>
<li>


<div id="Ramanarayanan2018">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Pautler, David,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Tsuprun, Eugene,
    
    
    
    
    
    
    
    Ubale, Rutuja,
    
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Toward Scalable Dialog Technology for Conversational Language Learning: Case Study of the TOEFL\textregistered MOOC.</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of Interspeech, 19th Annual Conference of the International Speech Communication Association,</em>
    

    
    2018
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ramanarayanan2018.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Pautler2018">
  

  
  <span class="author">
    
    
    
    
    Pautler, David,
    
    
    
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Cofino, Kirby,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Leveraging Multimodal Dialog Technology for the Design of Automated and Interactive Student Agents for Teacher Training</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc of SIGdial, 19th Annual Meeting of the the Special Interest Group on Discourse and Dialogue,</em>
    

    
    2018
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Pautler2018.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Evanini2018">
  

  
  <span class="author">
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    
    
    Timpe-Laughlin, Veronika,
    
    
    
    
    
    
    
    Tsuprun, Eugene,
    
    
    
    
    
    
    
    Blood, Ian,
    
    
    
    
    
    
    
    Lee, Jeremy,
    
    
    
    
    
    
    
    Bruno, James V,
    
    
    
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Game-based spoken dialog language learning applications for young students</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of INTERSPEECH, 19th Annual Conference of the International Speech Communication Association,</em>
    

    
    2018
    
  </span>

  
  

  <span class="links">
    
    [<a class="abstract">Abs</a>]
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Evanini2018.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>\textcopyright 2018 International Speech Communication Association. All rights reserved. This demo presents three different spoken dialog applications that were developed to provide young learners of English an opportunity to practice speaking and to receive feedback on particular aspects of their English speaking ability. The speaking tasks were designed as game-based interactions in order to engage young students, and they provide feedback about grammar (yes/no question formation and simple past tense verb formation) and vocabulary. A pilot study with 27 primary-level English as a foreign language (EFL) learners investigated the usefulness of these applications.</p>
  </span>
  
</div></li>
<li>


<div id="Qian2018">
  

  
  <span class="author">
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    
    
    Ubale, Rutuja,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    and
    
    
    Soong, Frank
    
    
    
    
  </span>
  

  <span class="title">From Speech Signals to Semantics—Tagging Performance at Acoustic, Phonetic and Word Levels</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of ISCSLP, 11th International Symposium on Chinese Spoken Language Processing,</em>
    

    
    2018
    
  </span>

  
  

  <span class="links">
    
    [<a class="abstract">Abs</a>]
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Qian2018.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>� 2018 IEEE Spoken language understanding (SLU) is to decode the semantic information embedded in speech input. SLU decoding can be significantly degraded by mismatched acoustic/language models between training and testing of a decoder. In this paper we investigate the semantic tagging performance of bidirectional LSTM RNN (BLSTM-RNN) with input at acoustic, phonetic and word levels. It is tested on a crowdsourced, spoken dialog speech corpus spoken by non-native speakers in a job interview task. The tagging performance is shown to be improved successively from low-level, acoustic MFCC, mid-level, stochastic senone posteriorgram, to high-level, ASR recognized word string, with the corresponding tagging accuracies at 70.6%, 82.1% and 85.1%, respectively. With a score fusion of the three individual RNNs together, the accuracy can be further improved to 87.0%.</p>
  </span>
  
</div></li>
<li>


<div id="Qian2017a">
  

  
  <span class="author">
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    
    
    Wang, Xinhao,
    
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    
    Pugh, Robert A. R.A.,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Molloy, Hillary R H.R. Hillary,
    
    
    
    
    
    and
    
    
    Soong, F.K. Frank K.
    
    
    
    
  </span>
  

  <span class="title">Improving Sub-Phone Modeling for Better Native Language Identification with Non-Native English Speech</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of Interspeech, 18th Annual Conference of the International Speech Communication Association,</em>
    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    [<a class="abstract">Abs</a>]
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Qian2017a.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Copyright \textcopyright 2017 ISCA. Identifying a speaker’s native language with his speech in a second language is useful for many human-machine voice interface applications. In this paper, we use a sub-phone-based i-vector approach to identify non-native English speakers’ native languages by their English speech input. Time delay deep neural networks (TDNN) are trained on LVCSR corpora for improving the alignment of speech utterances with their corresponding sub-phonemic "senone" sequences. The phonetic variability caused by a speaker’s native language can be better modeled with the sub-phone models than the conventional phone model based approach. Experimental results on the database released for the 2016 Interspeech ComParE Native Language challenge with 11 different L1s show that our system outperforms the best system by a large margin (87.2% UAR compared to 81.3% UAR for the best system from the 2016 ComParE challenge).</p>
  </span>
  
</div></li>
<li>


<div id="Qian2017b">
  

  
  <span class="author">
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    
    
    Ubale, Rutuja,
    
    
    
    
    
    
    
    Ramanaryanan, Vikram,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    and
    
    
    Tsuprun, Eugene
    
    
    
    
  </span>
  

  <span class="title">Exploring ASR-free end-to-end modeling to improve spoken language understanding in a cloud-based dialog system</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of ASRU, 15th IEEE Automatic Speech Recognition and Understanding Workshop,</em>
    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    [<a class="abstract">Abs</a>]
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Qian2017b.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>\textcopyright 2017 IEEE. Spoken language understanding (SLU) in dialog systems is generally performed using a natural language understanding (NLU) model based on the hypotheses produced by an automatic speech recognition (ASR) system. However, when new spoken dialog applications are built from scratch in real user environments that often have sub-optimal audio characteristics, ASR performance can suffer due to factors such as the paucity of training data or a mismatch between the training and test data. To address this issue, this paper proposes an ASR-free, end-to-end (E2E) modeling approach to SLU for a cloud-based, modular spoken dialog system (SDS). We evaluate the effectiveness of our approach on crowdsourced data collected from non-native English speakers interacting with a conversational language learning application. Experimental results show that our approach is particularly promising in situations with low ASR accuracy. It can further improve the performance of a sophisticated CNN-based SLU system with more accurate ASR hypotheses by fusing the scores from E2E system, i.e., the overall accuracy of SLU is improved from 85.6% to 86.5%.</p>
  </span>
  
</div></li>
<li>


<div id="Cofino2017">
  

  
  <span class="author">
    
    
    
    
    Cofino, Kirby,
    
    
    
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Pautler, David,
    
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    and
    
    
    Evanini, Keelan
    
    
    
    
  </span>
  

  <span class="title">A modular, multimodal open-source virtual interviewer dialog agent</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of ICMI, 19th ACM International Conference on Multimodal Interaction,</em>
    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    [<a class="abstract">Abs</a>]
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Cofino2017.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>\textcopyright 2017 ACM. We present an open-source multimodal dialog system equipped with a virtual human avatar interlocutor. The agent, rigged in Blender and developed in Unity with WebGL support, interfaces with the HALEF open-source cloud-based standard-compliant dialog framework. To demonstrate the capabilities of the system, we designed and implemented a conversational job interview scenario where the avatar plays the role of an interviewer and responds to user input in real-Time to provide an immersive user experience.</p>
  </span>
  
</div></li>
<li>


<div id="Qian2017c">
  

  
  <span class="author">
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Pugh, Robert,
    
    
    
    
    
    
    
    Ubale, Rutuja,
    
    
    
    
    
    and
    
    
    Soong, Frank K.
    
    
    
    
  </span>
  

  <span class="title">Improving native language (L1) identifation with better VAD and TDNN trained separately on native and non-native English corpora</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of the IEEE Automatic Speech Recognition and Understanding Workshop (ASRU),</em>
    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    [<a class="abstract">Abs</a>]
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Qian2017c.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>\textcopyright 2017 IEEE. Identifying a speaker’s native language (L1), i.e., mother tongue, based upon non-native English (L2) speech input, is both challenging and useful for many human-machine voice interface applications, e.g., computer assisted language learning (CALL). In this paper, we improve our sub-phone TDNN based i-vector approach to L1 recognition with a more accurate TDNN-derived VAD and a highly discriminative classifier. Two TDNNs are separately trained on native and non-native English, LVCSR corpora, for contrasting their corresponding sub-phone posteriors and resultant supervectors. The derived i-vectors are then exploited for improving the performance further. Experimental results on a database of 25 L1s show a 3.1% identification rate improvement, from 78.7% to 81.8%, compared with a high performance baseline system which has already achieved the best published results on the 2016 ComParE corpus of only 11 L1s. The statistical analysis of the features used in our system provides useful findings, e.g. pronunciation similarity among the non-native English speakers with different L1s, for research on second-language (L2) learning and assessment.</p>
  </span>
  
</div></li>
<li>


<div id="Loukina2017">
  

  
  <span class="author">
    
    
    
    
    Loukina, Anastassia,
    
    
    
    
    
    
    
    Beigman Klebanov, Beata,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Gyawali, Binod,
    
    
    
    
    
    and
    
    
    Qian, Yao
    
    
    
    
  </span>
  

  <span class="title">Developing speech processing technologies for shared book reading with a computer</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of WOCCI, 6th international workshop on child computer interaction,</em>
    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Loukina2017.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Ramanarayanan2017">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    
    
    Molloy, Hillary,
    
    
    
    
    
    
    
    Tsuprun, Eugene,
    
    
    
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Using Vision and Speech Features for Automated Prediction of Performance Metrics in Multimodal Dialogs</span>

  

  <span class="periodical">

    

    

    
    <em>ETS Research Report Series,</em>
    

    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ramanarayanan2017.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Suendermann-Oeft2017">
  

  
  <span class="author">
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Yu, Zhou,
    
    
    
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Wang, Xinhao,
    
    
    
    
    
    and
    
    
    Zechner, Klaus
    
    
    
    
  </span>
  

  <span class="title">A Multimodal Dialog System for Language Assessment: Current State and Future Directions</span>

  

  <span class="periodical">

    

    

    
    <em>ETS Research Report Series,</em>
    

    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Suendermann-Oeft2017.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Ramanarayanan2017b">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    
    Molloy, Hillary,
    
    
    
    
    
    
    
    Tsuprun, Eugene,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    and
    
    
    Evanini, Keelan
    
    
    
    
  </span>
  

  <span class="title">Crowdsourcing Multimodal Dialog Interactions: Lessons Learned from the HALEF Case</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of the Workshop on Crowdsourcing, Deep Learning and Artificial Intelligence Agents at the Thirty-First AAAI Conference on Artificial Intelligence,</em>
    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ramanarayanan2017b.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Qian2017">
  

  
  <span class="author">
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    
    
    Ubale, Rutuja,
    
    
    
    
    
    
    
    Ramanaryanan, Vikram,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    
    
    Tsuprun, Eugene,
    
    
    
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Suendermann‐Oeft, David,
    
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    and
    
    
    Tsuprun, Eugene
    
    
    
    
  </span>
  

  <span class="title">Towards End-to-End Modeling of Spoken Language Understanding in a Cloud-based Spoken Dialog System</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. pf SEMDAIL, 21st Workshop on the Semantics and Pragmatics of Dialogue,</em>
    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Qian2017.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Schnelle-Walka2017">
  

  
  <span class="author">
    
    
    
    
    Schnelle-Walka, Dirk,
    
    
    
    
    
    
    
    Radomski, Stefan,
    
    
    
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    
    Radomski, Stefan,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    and
    
    
    Suendermann‐Oeft, David
    
    
    
    
  </span>
  

  <span class="title">An Open Source Standards-Compliant Voice Browser with Support for Multiple Language Understanding Implementations</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of SEMDIAL, 21st Workshop on the Semantics and Pragmatics of Dialogue,</em>
    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Schnelle-Walka2017.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Ramanarayanan2017c">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    
    
    Molloy, Hillary,
    
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Human and Automated Scoring of Fluency, Pronunciation and Intonation During Human – Machine Spoken Dialog Interactions</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of Interspeech, 18th Annual Conference of the International Speech Communication Association,</em>
    

    
    2017
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ramanarayanan2017c.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Ramanarayanan2016">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Ivanov, Alexei V.,
    
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    
    
    Yu, Zhou,
    
    
    
    
    
    
    
    Tsuprun, Eugene,
    
    
    
    
    
    and
    
    
    Qian, Yao
    
    
    
    
  </span>
  

  <span class="title">Bootstrapping Development of a Cloud-Based Spoken Dialog System in the Educational Domain From Scratch Using Crowdsourced Data</span>

  

  <span class="periodical">

    

    

    
    <em>ETS Research Report Series,</em>
    

    

    
    2016
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ramanarayanan2016.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Ivanov2016">
  

  
  <span class="author">
    
    
    
    
    Ivanov, Alexei V.,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    
    
    Yu, Zhou,
    
    
    
    
    
    and
    
    
    Tao, Jidong
    
    
    
    
  </span>
  

  <span class="title">Speed vs. Accuracy: Designing an Optimal ASR System for Spontaneous Non-Native Speech in a Real-Time Application</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of IWSDS, International Workshop on Spoken Dialog Systems,</em>
    

    
    2016
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ivanov2016.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Ivanov2016a">
  

  
  <span class="author">
    
    
    
    
    Ivanov, Alexei V.,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">LVCSR System on a Hybrid GPU-CPU Embedded Platform for Real-Time Dialog Applications</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of SIGdial, 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,</em>
    

    
    2016
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ivanov2016a.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Ramanarayanan2016a">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Mundkowsky, Robert,
    
    
    
    
    
    
    
    Ivanov, Alexei V.,
    
    
    
    
    
    
    
    Yu, Zhou,
    
    
    
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    and
    
    
    Evanini, Keelan
    
    
    
    
  </span>
  

  <span class="title">Development of an Audiovisual Database of Human-Machine Conversations for Educational Learning and Assessment Applications</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of CMLA, Workshop on Computational Models for Learning Systems and Educational Assessment,</em>
    

    
    2016
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ramanarayanan2016a.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Ramanarayanan2016b">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Pautler, David,
    
    
    
    
    
    
    
    Yu, Zhou,
    
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    
    Intention Perception, L L C,
    
    
    
    
    
    and
    
    
    Suendermann‐Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Interview with an Avatar: A Real-Time Engagement Tracking-Enabled Cloud-Based Multimodal Dialog System for Learning and Assessment</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of SLT, IEEE Workshop on Spoken Language Technology,</em>
    

    
    2016
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ramanarayanan2016b.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Ivanov2015">
  

  
  <span class="author">
    
    
    
    
    Ivanov, Alexei V.,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Fast and Power Efficient Hardware-Accelerated Cloud-Based ASR for Remote Dialog Applications</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of ASRU, 14th IEEE Automatic Speech Recognition and Understanding Workshop,</em>
    

    
    2015
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ivanov2015.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Ramanarayanan2015">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Yu, Zhou,
    
    
    
    
    
    
    
    Mundkowsky, Robert,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Ivanov, Alexei V.,
    
    
    
    
    
    
    
    Black, Alan W.,
    
    
    
    
    
    
    
    Suendermann‐Oeft, David,
    
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">A Modular Open-Source Standard-Compliant Dialog System Framework with Video Support</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of ASRU, 14th IEEE Automatic Speech Recognition and Understanding Workshop,</em>
    

    
    2015
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ramanarayanan2015.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Lange2014">
  

  
  <span class="author">
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Tuning Sphinx to Outperform Google’s Speech Recognition API</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of ESSV, Conference on Electronic Speech Signal Processing,</em>
    

    
    2014
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Lange2014.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Mory2014">
  

  
  <span class="author">
    
    
    
    
    Mory, Martin,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Mehrez, Tarek,
    
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Evaluation of Freely Available Speech Synthesis Voices for Halef</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of NLPCS, Natural Language Processing and Cognitive Science,</em>
    

    
    2014
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Mory2014.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Mehrez2013">
  

  
  <span class="author">
    
    
    
    
    Mehrez, Tarek,
    
    
    
    
    
    
    
    Abdelkawy, Abdelrahman,
    
    
    
    
    
    
    
    Heikal, Youmna,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Nabil, Hadeer,
    
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Who Discovered the Electron Neutrino? A Telephony-Based Distributed Open-Source Standard-Compliant Spoken Dialog System for Question Answering</span>

  

  <span class="periodical">

    

    

    

    
    In <em>Proc. of GSCL, International Conference of the German Society for Computational Linguistics and Language Technology,</em>
    

    
    2013
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Mehrez2013.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li></ol>

<h3 id="theses" class="category">Theses</h3>
<ol class="bibliography"><li>


<div id="Lange2015">
  

  
  <span class="author">
    
    
    <em>Lange, Patrick L.</em>
    
    
  </span>
  

  <span class="title">Prototyping a Language Model for the Transcription of German Medical Reports: An Empirical Study</span>

  
  <span class="author">
    Advisors: Sharp, Bernadette and Suendermann-Oeft, David
  </span>
  

  <span class="periodical">

    

    
    <em>Staffordshire University, UK,</em>
    

    

    

    
    2015
    
  </span>

  
  <span class="author">
    Thesis for the Award of Masters by Research in Computing Science
  </span>
  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Lange2015.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li></ol>

<h3 id="patents" class="category">Patents</h3>
<ol class="bibliography"><li>


<div id="Ramanarayanan2020">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Ivanov, Alexei V.,
    
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    and
    
    
    Yu, Zhou
    
    
    
    
  </span>
  

  <span class="title">Computer-implemented systems and methods for a crowd source-bootstrapped spoken dialog system</span>

  

  <span class="periodical">

    

    

    

    

    
    2020
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://patentimages.storage.googleapis.com/01/47/31/9d9237c8165aa3/US10607504.pdf" target="_blank">LINK</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="ramanarayanan2020computer">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    
    
    Ivanov, Alexei V.,
    
    
    
    
    
    
    
    Evanini, Keelan,
    
    
    
    
    
    
    
    Qian, Yao,
    
    
    
    
    
    
    
    Tsuprun, Eugene,
    
    
    
    
    
    and
    
    
    Molloy, Hillary R.
    
    
    
    
  </span>
  

  <span class="title">Computer-implemented systems and methods for evaluating speech dialog system engagement via video</span>

  

  <span class="periodical">

    

    

    

    

    
    2020
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://patents.google.com/patent/US10592733B1/en" target="_blank">LINK</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li></ol>

<h3 id="reports" class="category">Reports</h3>
<ol class="bibliography"><li>


<div id="Ramanarayanan2018a">
  

  
  <span class="author">
    
    
    
    
    Ramanarayanan, Vikram,
    
    
    
    
    
    
    
    Pautler, David,
    
    
    
    
    
    
    <em>Lange, Patrick</em>,
    
    
    
    
    and
    
    
    Suendermann-Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Interview With an Avatar: A Real-Time Cloud-Based Virtual Dialog Agent for Educational and Job Training Applications</span>

  

  <span class="periodical">

    
    <em>Research Report,</em>
    

    

    
    <em>ETS Research Memorandum,</em>
    

    

    
    2018
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Ramanarayanan2018a.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li>
<li>


<div id="Gaida2014">
  

  
  <span class="author">
    
    
    
    
    Gaida, Christian,
    
    
    
    
    
    
    <em>Lange, Patrick L.</em>,
    
    
    
    
    
    
    Petrick, Rico,
    
    
    
    
    
    
    
    Proba, Patrick,
    
    
    
    
    
    
    
    Malatawy, Ahmed,
    
    
    
    
    
    
    
    Suendermann-Oeft, David,
    
    
    
    
    
    and
    
    
    Suendermann‐Oeft, David
    
    
    
    
  </span>
  

  <span class="title">Comparing Open-Source Speech Recognition Toolkits</span>

  

  <span class="periodical">

    
    <em>Technical Report,</em>
    

    

    

    

    
    2014
    
  </span>

  
  

  <span class="links">
    
    
    
    
    [<a href="https://www.langep.com/assets/pdf/Gaida2014.pdf" target="_blank">PDF</a>]
    
    
    
    
    
  </span>

  <!-- Hidden abstract block -->
  
</div></li></ol>

  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2020 Patrick Lange.
    
        Last updated: 2019-03-10.
    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="https://www.langep.com/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
<script src="https://www.langep.com/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://www.langep.com/assets/css/font-awesome.min.css">
<link rel="stylesheet" href="https://www.langep.com/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-86140203-1', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
